{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f0d8965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/jeongmingyeong/anaconda3/envs/ML/lib/python3.10/site-packages (3.8.1)\r\n",
      "Requirement already satisfied: click in /Users/jeongmingyeong/anaconda3/envs/ML/lib/python3.10/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /Users/jeongmingyeong/anaconda3/envs/ML/lib/python3.10/site-packages (from nltk) (1.2.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/jeongmingyeong/anaconda3/envs/ML/lib/python3.10/site-packages (from nltk) (2024.5.15)\r\n",
      "Requirement already satisfied: tqdm in /Users/jeongmingyeong/anaconda3/envs/ML/lib/python3.10/site-packages (from nltk) (4.66.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5185d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/jeongmingyeong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e457294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "with open(\"data.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "    for doc in text.split(\"---\"):\n",
    "        doc = doc.lower() \n",
    "        tokens = word_tokenize(doc)\n",
    "        docs.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ada63ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\"\"\"\n",
    "    Implement this function.\n",
    "    Arguments.\n",
    "        docs: a list of token lists\n",
    "\n",
    "    Returns\n",
    "        tfidf_dict: dict, key is word, value is tfidf score.\n",
    "\"\"\"\n",
    "def compute_tfidf(docs):\n",
    "    # tfidf_dict : 단어별로 docs의 doc 개수만큼의 tfidf값을 저장할 수 있음.\n",
    "    tfidf_dict = {}\n",
    "    for d in docs:\n",
    "        for t in d:\n",
    "            if t not in tfidf_dict:\n",
    "                tfidf_dict[t] = [0 for _ in range(len(docs))] # initialize\n",
    "    # Implement here! \n",
    "    \n",
    "    # N : size of docs (== 총 문서의 수)\n",
    "    N = len(docs)\n",
    "    \n",
    "    \n",
    "    # tf() : calculate tf value (== frequency count of term in doc)\n",
    "    # t : term, d : doc (p.50 참고)\n",
    "    def tf(t, d):\n",
    "        return d.count(t)\n",
    "    \n",
    "    \n",
    "    # idf() : calculate idf value (== higher weight to rare term)\n",
    "    # idf = 1 + log(총 문서의 수 / term을 포함하는 문서의 수)\n",
    "    # t : term, doc : docs list\n",
    "    def idf(t, doc):\n",
    "        # 해당 term을 포함하는 문서의 수\n",
    "        df = 0\n",
    "        for d in doc:\n",
    "            df += 1 if t in d else 0\n",
    "        # 최종 idf 반환\n",
    "        return (1 + math.log(N / df))\n",
    "    \n",
    "    idx = -1 # 몇번째 doc의 tfidf인지를 나타냄.\n",
    "    # 최종 tfidf 계산해 저장\n",
    "    for d in docs:\n",
    "        idx += 1\n",
    "        for t in d:\n",
    "            tfidf_dict[t][idx] = tf(t, d) * idf(t, docs)\n",
    "\n",
    "    \n",
    "    return tfidf_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "304acf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3.6390573296152584, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] [0, 0, 0, 0, 0, 0, 0, 13.516577810972208, 13.516577810972208, 6.758288905486104, 13.516577810972208, 0, 0, 0] [0, 0, 0, 3.6390573296152584, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "tfidf_dict = compute_tfidf(docs)\n",
    "print(tfidf_dict[\"gpu\"], tfidf_dict[\"beer\"], tfidf_dict[\"make\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
