{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2018c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset 에 대한 분류문제\n",
    "# import package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# MNIST dataset 을 불러오기 위해 import\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82b2011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU / CPU setting\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb013bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor형으로 data 불러옴.\n",
    "# 처음 불러오는거면 download 함.\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform = transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f63d361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch generation\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c992b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "torch.Size([100, 1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n",
      "tensor(1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, data in enumerate(train_loader):\n",
    "    x, y = data\n",
    "    print(y.shape) # batch size = 100개의 data가 들어가 있음.\n",
    "    print(x.shape) # batch size, channel(gray==1), 가로 세로 사이즈\n",
    "    print(x[0].shape)\n",
    "    print(y[0])\n",
    "    plt.imshow(x[0][0].reshape(28, 28), cmap='gray')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "935c567d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model generate\n",
    "class MLP_model(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP_model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # linear layer 정의 (fc : fully-connected)\n",
    "        self.fc1 = torch.nn.Linear(input_size, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 256)\n",
    "        self.fc3 = torch.nn.Linear(256, num_classes)\n",
    "        \n",
    "        # activation function 정의 (불러올 수 있는 함수이므로 따로 정의하지 않아도 됨.)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        ac1 = self.relu(fc1)\n",
    "        \n",
    "        fc2 = self.fc2(ac1)\n",
    "        ac2 = self.relu(fc2)\n",
    "        \n",
    "        output = self.fc3(ac2)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe9e40f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter definition\n",
    "input_size = 784  # 28 * 28\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de035da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "model = MLP_model(input_size, num_classes).to(device) # model을 device에 올려주겠다.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "93e314cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.02588\n",
      "Epoch 2 Loss 0.02280\n",
      "Epoch 3 Loss 0.01892\n",
      "Epoch 4 Loss 0.01698\n",
      "Epoch 5 Loss 0.01489\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "loss_list = [] # loss를 출력하기 위함.\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0 # batch마다의 cost를 더해서 평균을 내줌.\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        x_data = x_data.reshape(-1, 28*28) # [100, 1, 28, 28] -> [100, 784]\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss=criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53d10fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 98.11000%\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "with torch.no_grad(): # validation용이니까 gradient를 계산하지 말아라 -> 연산부담 줄여줌.\n",
    "    num_total_data = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # softmax function을 통과시켜서 결과 Get\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model accuracy {:.5f}%\".format((correct/num_total_data)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0d67a",
   "metadata": {},
   "source": [
    "## practice2 . DIGIT recognition with sequential API (model 정의만 다름)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad4d64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와는 다른 방법의 model 정의\n",
    "linear1 = nn.Linear(784, 256)\n",
    "linear2 = nn.Linear(256, 64)\n",
    "linear3 = nn.Linear(64, 10)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ef02af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터, 손실함수, optimizer 정의\n",
    "epoch = 5\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "79888c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.59381\n",
      "Epoch 2 Loss 0.23500\n",
      "Epoch 3 Loss 0.16660\n",
      "Epoch 4 Loss 0.12818\n",
      "Epoch 5 Loss 0.10252\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "loss_list = [] # loss를 출력하기 위함.\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0 # batch마다의 cost를 더해서 평균을 내줌.\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        x_data = x_data.reshape(-1, 28*28) # [100, 1, 28, 28] -> [100, 784]\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss=criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03786d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 96.83000%\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "with torch.no_grad(): # validation용이니까 gradient를 계산하지 말아라 -> 연산부담 줄여줌.\n",
    "    num_total_data = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # softmax function을 통과시켜서 결과 Get\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model accuracy {:.5f}%\".format((correct/num_total_data)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
