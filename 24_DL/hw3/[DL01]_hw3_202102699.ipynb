{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67425e20",
   "metadata": {},
   "source": [
    "# prac1 : DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "292ae354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58a4853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2644d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform = transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e322c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f8ec142",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model ##\n",
    "class MLP_Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_Dropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.dp1 = nn.Dropout(p = 0.4)\n",
    "        self.dp2 = nn.Dropout(p = 0.2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        h1dp = self.dp1(h1)\n",
    "        h2 = F.relu(self.fc2(h1dp))\n",
    "        h2dp = self.dp2(h2)\n",
    "        output = self.fc3(h2dp)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e1fda18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameter, model\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = MLP_Dropout().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1c5fac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.37455\n",
      "Epoch 2 Loss 0.27538\n",
      "Epoch 3 Loss 0.24111\n",
      "Epoch 4 Loss 0.23204\n",
      "Epoch 5 Loss 0.23526\n",
      "Epoch 6 Loss 0.21981\n",
      "Epoch 7 Loss 0.21843\n",
      "Epoch 8 Loss 0.21434\n",
      "Epoch 9 Loss 0.21188\n",
      "Epoch 10 Loss 0.19830\n"
     ]
    }
   ],
   "source": [
    "## model train\n",
    "loss_list = []\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0\n",
    "    model.train() # set model for train\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        \n",
    "        x_data = x_data.reshape(-1, 28*28)\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss = criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item() / num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d11488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 96.69000%\n"
     ]
    }
   ],
   "source": [
    "## model validation\n",
    "with torch.no_grad():\n",
    "    num_total_data = 0\n",
    "    correct = 0 \n",
    "    model.eval() # set model for test\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model accuracy {:.5f}%\".format((correct / num_total_data)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135167c3",
   "metadata": {},
   "source": [
    "# prac2 : Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "194f9dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ae9c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b8ff4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform = transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d6f6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6dd4cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Model\n",
    "class Batch_Norm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Batch_Norm, self).__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(nn.Linear(784, 256),\n",
    "                                    nn.BatchNorm1d(256),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(256, 64),\n",
    "                                    nn.BatchNorm1d(64),\n",
    "                                    nn.ReLU(),\n",
    "                                    nn.Linear(64, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.network(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7bfb3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "num_epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = Batch_Norm().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93cf4ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.19244\n",
      "Epoch 2 Loss 0.08821\n",
      "Epoch 3 Loss 0.06432\n",
      "Epoch 4 Loss 0.05081\n",
      "Epoch 5 Loss 0.04461\n",
      "Epoch 6 Loss 0.03755\n",
      "Epoch 7 Loss 0.03308\n",
      "Epoch 8 Loss 0.02928\n",
      "Epoch 9 Loss 0.02511\n",
      "Epoch 10 Loss 0.02480\n"
     ]
    }
   ],
   "source": [
    "## model train\n",
    "loss_list = []\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0\n",
    "    model.train() # set model for train\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        \n",
    "        x_data = x_data.reshape(-1, 28*28)\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss = criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item() / num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "531b3d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 97.85000%\n"
     ]
    }
   ],
   "source": [
    "## model validation\n",
    "with torch.no_grad():\n",
    "    num_total_data = 0\n",
    "    correct = 0 \n",
    "    model.eval() # set model for test\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model accuracy {:.5f}%\".format((correct / num_total_data)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5c2a4",
   "metadata": {},
   "source": [
    "# Homework : Generate a classification model for MNIST dataset (99%)\n",
    "\n",
    "- model 성능 : 최종 98.28%\n",
    "- model 구조\n",
    "    1. input layer 1개, hidden layer 2개, output layer 1개로 총 4개\n",
    "    2. activation function : leaky ReLU 사용\n",
    "    3. epoch은 30, learning rate 는 0.05로 설정한 후 overfitting 을 막기 위해 dropout 방법 사용\n",
    "    4. 실습때 사용해본 dropout과 batch nomalization을 함께 사용해봄. (다다익선일 수 있으니 두가지의 규제방법 함께 사용)\n",
    "\n",
    "\n",
    "- 규제방법을 두가지를 함께 사용했으니 좀 더 학습시켜도 될 것 같아 hidden layer 를 하나 더 추가해보았고 epoch 수도 늘려보았다. ReLU function도 음수일때 activation zero 가 되는 문제가 있다 했으니 leaky ReLU 로 변경해 사용해보았다. 실습에서 구축한 모델에 비해 성능은 약간 좋아졌지만, 큰 차이가 나지 않는다. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a21aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "402ab640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3f2dc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform = transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6877cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8c7b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model2 ##\n",
    "class MLP_Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP_Dropout, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        self.dp1 = nn.Dropout(p = 0.4)\n",
    "        self.dp2 = nn.Dropout(p = 0.2)\n",
    "        self.dp3 = nn.Dropout(p = 0.1)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h1 = F.leaky_relu(self.bn1(self.fc1(x)))\n",
    "        h1dp = self.dp1(h1)\n",
    "        h2 = F.leaky_relu(self.bn2(self.fc2(h1dp)))\n",
    "        h2dp = self.dp2(h2)\n",
    "        h3 = F.leaky_relu(self.bn3(self.fc3(h2dp)))\n",
    "        h3dp = self.dp3(h3)\n",
    "        output = self.fc4(h3dp)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0822c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "num_epochs = 30\n",
    "learning_rate = 0.005\n",
    "\n",
    "model = Batch_Norm().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "228afd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 0.18972\n",
      "Epoch 2 Loss 0.08377\n",
      "Epoch 3 Loss 0.05802\n",
      "Epoch 4 Loss 0.04754\n",
      "Epoch 5 Loss 0.03720\n",
      "Epoch 6 Loss 0.03243\n",
      "Epoch 7 Loss 0.02795\n",
      "Epoch 8 Loss 0.02512\n",
      "Epoch 9 Loss 0.02433\n",
      "Epoch 10 Loss 0.01980\n",
      "Epoch 11 Loss 0.01772\n",
      "Epoch 12 Loss 0.01779\n",
      "Epoch 13 Loss 0.01542\n",
      "Epoch 14 Loss 0.01266\n",
      "Epoch 15 Loss 0.01631\n",
      "Epoch 16 Loss 0.01287\n",
      "Epoch 17 Loss 0.01284\n",
      "Epoch 18 Loss 0.01271\n",
      "Epoch 19 Loss 0.01049\n",
      "Epoch 20 Loss 0.01165\n",
      "Epoch 21 Loss 0.01248\n",
      "Epoch 22 Loss 0.00763\n",
      "Epoch 23 Loss 0.00821\n",
      "Epoch 24 Loss 0.00933\n",
      "Epoch 25 Loss 0.00937\n",
      "Epoch 26 Loss 0.00836\n",
      "Epoch 27 Loss 0.00792\n",
      "Epoch 28 Loss 0.00670\n",
      "Epoch 29 Loss 0.00974\n",
      "Epoch 30 Loss 0.00859\n"
     ]
    }
   ],
   "source": [
    "## model train\n",
    "loss_list = []\n",
    "\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0\n",
    "    model.train() # set model for train\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        \n",
    "        x_data = x_data.reshape(-1, 28*28)\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss = criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item() / num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20ccc2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 98.28000%\n"
     ]
    }
   ],
   "source": [
    "## model validation\n",
    "with torch.no_grad():\n",
    "    num_total_data = 0\n",
    "    correct = 0 \n",
    "    model.eval() # set model for test\n",
    "    \n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model accuracy {:.5f}%\".format((correct / num_total_data)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
