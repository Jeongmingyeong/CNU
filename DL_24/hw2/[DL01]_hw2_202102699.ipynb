{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db496c82",
   "metadata": {},
   "source": [
    "## hw2-1 : MNIST dataset에 대해 분류하는 모델 2가지 생성(torch.nn.Module)\n",
    "실습의 torch.nn.Module 을 사용하였고, activation function 을 ReLU 에서 Sigmoid function 으로 변경한 모델로 test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83591708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset 에 대한 분류문제\n",
    "# import package\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "# MNIST dataset 을 불러오기 위해 import\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79f1b927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# GPU / CPU setting\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31454865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor형으로 data 불러옴.\n",
    "# 처음 불러오는거면 download 함.\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform = transforms.ToTensor(), download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform = transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0325712c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch generation\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f6c352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model generate - activation function : sigmoid\n",
    "class MLP_model(torch.nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(MLP_model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # linear layer 정의 (fc : fully-connected)\n",
    "        self.fc1 = torch.nn.Linear(input_size, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 256)\n",
    "        self.fc3 = torch.nn.Linear(256, num_classes)\n",
    "        \n",
    "        # activation function 정의 (불러올 수 있는 함수이므로 따로 정의하지 않아도 됨.)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        ac1 = self.sigmoid(fc1)\n",
    "        \n",
    "        fc2 = self.fc2(ac1)\n",
    "        ac2 = self.sigmoid(fc2)\n",
    "        \n",
    "        output = self.fc3(ac2)\n",
    "        \n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92c048e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter definition\n",
    "input_size = 784  # 28 * 28\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c095d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "model = MLP_model(input_size, num_classes).to(device) # model을 device에 올려주겠다.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa96a149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss 2.23597\n",
      "Epoch 2 Loss 1.10197\n",
      "Epoch 3 Loss 0.59271\n",
      "Epoch 4 Loss 0.44549\n",
      "Epoch 5 Loss 0.39027\n",
      "Epoch 6 Loss 0.35969\n",
      "Epoch 7 Loss 0.34006\n",
      "Epoch 8 Loss 0.32449\n",
      "Epoch 9 Loss 0.31045\n",
      "Epoch 10 Loss 0.29731\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "loss_list = [] # loss를 출력하기 위함.\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0 # batch마다의 cost를 더해서 평균을 내줌.\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        x_data = x_data.reshape(-1, 28*28) # [100, 1, 28, 28] -> [100, 784]\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss=criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89e17e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy 91.65000%\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "with torch.no_grad(): # validation용이니까 gradient를 계산하지 말아라 -> 연산부담 줄여줌.\n",
    "    num_total_data = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # softmax function을 통과시켜서 결과 Get\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model accuracy {:.5f}%\".format((correct/num_total_data)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deed605",
   "metadata": {},
   "source": [
    "## hw2-2 : MNIST dataset에 대해 분류하는 모델 2가지 생성 (sequential API 사용)\n",
    "실습의 sequential API를 사용하였고, activation function 을 ReLU 에서 Sigmoid function 으로 변경한 모델로 test\n",
    "\n",
    "sigmoid function을 사용하여 test를 했을 때 정확도가 11%정도로 매우 낮게 나왔기 때문에 같은 모델에서 activation function만을 ReLU로 변경해서 비교진행\n",
    "\n",
    "같은 layer 로 구성되어있는 모델에서 activation function만 변경해서 비교했을 때 MNIST dataset 에 대한 accuracy가 \n",
    "\n",
    "- sigmoid function : 약 11%\n",
    "- ReLU function : 약 98%\n",
    "\n",
    "정도로 차이가 많이 난다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c547f634",
   "metadata": {},
   "source": [
    "### 1) activation function을 sigmoid로 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfccc04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와는 다른 방법의 model 정의 - activation function : sigmoid\n",
    "linear1 = nn.Linear(784, 256)\n",
    "linear2 = nn.Linear(256, 256)\n",
    "linear3 = nn.Linear(256, 64)\n",
    "linear4 = nn.Linear(64, 64)\n",
    "linear5 = nn.Linear(64, 10)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid, linear5)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82237540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터, 손실함수, optimizer 정의\n",
    "epoch = 10\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f1244b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid : Epoch 1 Loss 2.30542\n",
      "Sigmoid : Epoch 2 Loss 2.30511\n",
      "Sigmoid : Epoch 3 Loss 2.30485\n",
      "Sigmoid : Epoch 4 Loss 2.30450\n",
      "Sigmoid : Epoch 5 Loss 2.30443\n",
      "Sigmoid : Epoch 6 Loss 2.30409\n",
      "Sigmoid : Epoch 7 Loss 2.30384\n",
      "Sigmoid : Epoch 8 Loss 2.30358\n",
      "Sigmoid : Epoch 9 Loss 2.30365\n",
      "Sigmoid : Epoch 10 Loss 2.30313\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "loss_list = [] # loss를 출력하기 위함.\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0 # batch마다의 cost를 더해서 평균을 내줌.\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        x_data = x_data.reshape(-1, 28*28) # [100, 1, 28, 28] -> [100, 784]\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss=criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"Sigmoid : Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8e6333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (with sigmoid) accuracy 11.35000%\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "with torch.no_grad(): # validation용이니까 gradient를 계산하지 말아라 -> 연산부담 줄여줌.\n",
    "    num_total_data = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # softmax function을 통과시켜서 결과 Get\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model (with sigmoid) accuracy {:.5f}%\".format((correct/num_total_data)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21510ee5",
   "metadata": {},
   "source": [
    "### 2) activation function을 ReLU로 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e8bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와는 다른 방법의 model 정의 - activation function : sigmoid\n",
    "linear1 = nn.Linear(784, 256)\n",
    "linear2 = nn.Linear(256, 256)\n",
    "linear3 = nn.Linear(256, 64)\n",
    "linear4 = nn.Linear(64, 64)\n",
    "linear5 = nn.Linear(64, 10)\n",
    "sigmoid = torch.nn.Sigmoid()\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3, relu, linear4, relu, linear5)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "211f8a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터, 손실함수, optimizer 정의\n",
    "epoch = 10\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c25ba9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU : Epoch 1 Loss 1.26870\n",
      "ReLU : Epoch 2 Loss 0.23227\n",
      "ReLU : Epoch 3 Loss 0.13513\n",
      "ReLU : Epoch 4 Loss 0.09763\n",
      "ReLU : Epoch 5 Loss 0.07550\n",
      "ReLU : Epoch 6 Loss 0.06166\n",
      "ReLU : Epoch 7 Loss 0.04886\n",
      "ReLU : Epoch 8 Loss 0.03918\n",
      "ReLU : Epoch 9 Loss 0.03211\n",
      "ReLU : Epoch 10 Loss 0.02705\n"
     ]
    }
   ],
   "source": [
    "# model train\n",
    "loss_list = [] # loss를 출력하기 위함.\n",
    "for epoch_num in range(num_epochs):\n",
    "    average_cost = 0 # batch마다의 cost를 더해서 평균을 내줌.\n",
    "    \n",
    "    for batch_idx, (x_data, y_label) in enumerate(train_loader):\n",
    "        num_of_mini_batch = len(train_loader)\n",
    "        x_data = x_data.reshape(-1, 28*28) # [100, 1, 28, 28] -> [100, 784]\n",
    "        input_image = x_data.to(device)\n",
    "        label = y_label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_predict = model(input_image)\n",
    "        loss=criterion(y_predict, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        average_cost = average_cost + (loss.item()/num_of_mini_batch)\n",
    "        loss_list.append(loss)\n",
    "        \n",
    "    print(\"ReLU : Epoch {} Loss {:.5f}\".format((epoch_num+1), average_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4281e643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (with ReLU) accuracy 97.72000%\n"
     ]
    }
   ],
   "source": [
    "# validation\n",
    "with torch.no_grad(): # validation용이니까 gradient를 계산하지 말아라 -> 연산부담 줄여줌.\n",
    "    num_total_data = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # softmax function을 통과시켜서 결과 Get\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        predicted = torch.argmax(outputs_softmax, dim=1)\n",
    "        \n",
    "        num_total_data += len(images)\n",
    "        answer = sum(labels==predicted).item()\n",
    "        correct += answer\n",
    "        \n",
    "print(\"Model (with ReLU) accuracy {:.5f}%\".format((correct/num_total_data)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
